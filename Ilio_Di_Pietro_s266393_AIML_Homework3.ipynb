{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.3.1'\n",
        "!pip3 install 'torchvision==0.4.2'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "**Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.hub\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch.hub import load_state_dict_from_url\n",
        "from torch.autograd import Function\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIDLJuIXK_vh",
        "colab_type": "text"
      },
      "source": [
        "**Set Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5PkYfqfK_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEVICE = 'cuda' \n",
        "\n",
        "NUM_CLASSES = 7 \n",
        "NUM_DOMAINS = 2\n",
        "\n",
        "#hyperparameters for AlexNet without dann\n",
        "LR         = [1e-3, 2e-3, 5e-3, 1e-2, 1e-3, 2e-3, 5e-3, 1e-2]\n",
        "BATCH_SIZE = [128,  128,  128,  128,  256,  256,  256,  256] \n",
        "NUM_EPOCHS = [15,   15,   15,   15,   15,   15,   15,   15]     \n",
        "STEP_SIZE  = [10,   10,   10,   10,   10,   10,   10,   10] \n",
        "\n",
        "#hyperparameters for AlexNet with dann\n",
        "LR_DANN         = [1e-3, 5e-3, 1e-2] \n",
        "BATCH_SIZE_DANN = [128, 256]  \n",
        "NUM_EPOCHS_DANN = 15     \n",
        "STEP_SIZE_DANN  = 10\n",
        "ALPHA           = [1e-2, 5e-2, 1e-1]\n",
        "\n",
        "MOMENTUM = 0.9      \n",
        "WEIGHT_DECAY = 5e-5  \n",
        "GAMMA = 0.1          \n",
        "LOG_FREQUENCY = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX0hoBl_dXnC",
        "colab_type": "text"
      },
      "source": [
        "**DANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvbm1nqtdbO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "__all__ = ['DANN', 'dann']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'dann': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    # Forwards identity\n",
        "    # Sends backward reversed gradients\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        return output, None\n",
        "\n",
        "class DANN(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(DANN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.Gy = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "        self.Gd = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, alpha=None):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        # If we pass alpha, we can assume we are training the discriminator\n",
        "        if alpha is not None:\n",
        "            # gradient reversal layer (backward gradients will be reversed)\n",
        "            reverse_feature = ReverseLayerF.apply(x, alpha)\n",
        "            discriminator_output = self.Gd(reverse_feature)\n",
        "            return discriminator_output\n",
        "        # If we don't pass alpha, we assume we are training with supervision\n",
        "        else:\n",
        "            # do something else\n",
        "            class_outputs = self.Gy(x)\n",
        "            return class_outputs\n",
        "\n",
        "def dann(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    model = DANN(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['dann'], progress = progress)\n",
        "        model.load_state_dict(state_dict, strict = False)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "**Define Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUDdw4j2H0Mc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalize = transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
        "train_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      normalize,])\n",
        "\n",
        "eval_transform = transforms.Compose([transforms.Resize(256),\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      normalize,])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "**Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Homework3-PACS'):\n",
        "  !git clone https://github.com/MachineLearning2020/Homework3-PACS.git\n",
        "\n",
        "DATA_DIR = 'Homework3-PACS/PACS'\n",
        "DATA_DIR_SOURCE = 'Homework3-PACS/PACS/photo'\n",
        "DATA_DIR_TARGET = 'Homework3-PACS/PACS/art_painting'\n",
        "\n",
        "# Prepare Pytorch train/test Datasets for alexnet\n",
        "train_dataset = torchvision.datasets.ImageFolder(DATA_DIR_SOURCE, transform = train_transform)\n",
        "test_dataset  = torchvision.datasets.ImageFolder(DATA_DIR_TARGET, transform = eval_transform)\n",
        "\n",
        "#Prepare Source and Target for dann\n",
        "source_dataset = torchvision.datasets.ImageFolder(DATA_DIR_SOURCE, transform = train_transform)\n",
        "target_dataset = torchvision.datasets.ImageFolder(DATA_DIR_TARGET, transform = train_transform)\n",
        "\n",
        "#validation\n",
        "DATA_DIR_VAL_C = 'Homework3-PACS/PACS/cartoon'\n",
        "DATA_DIR_VAL_S = 'Homework3-PACS/PACS/sketch'\n",
        "\n",
        "val_cartoon = torchvision.datasets.ImageFolder(DATA_DIR_VAL_C, transform = eval_transform)\n",
        "val_sketch  = torchvision.datasets.ImageFolder(DATA_DIR_VAL_S, transform = eval_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze1HdGbCXc9q",
        "colab_type": "text"
      },
      "source": [
        "**Computation of accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDOOPDTzXg9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_accuracy(net, dataloader, type_of_set):  \n",
        "    # check accuracy on whole test set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    net.train(False)  \n",
        "    with torch.no_grad(): \n",
        "        for data in dataloader:\n",
        "            images, labels = data\n",
        "            images = images.to(DEVICE)\n",
        "            labels = labels.to(DEVICE)\n",
        "            outputs = net(images)  # predictions\n",
        "            _, predicted = torch.max(outputs.data, 1)  # predicted labels\n",
        "            total += labels.size(0)\n",
        "            correct += torch.sum(predicted == labels.data).data.item()  # compare with ground truth\n",
        "    accuracy = 100 * correct / total\n",
        "    print('Accuracy of the network on the %s set: %.3f %%' %(type_of_set, accuracy))\n",
        "    net.train(True)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icpN9eQpJIM7",
        "colab_type": "text"
      },
      "source": [
        "**print losses**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrBgyalB8jWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_loss(loss, title):\n",
        "  plt.plot(loss, 'b', label =  title) \n",
        "  plt.legend(loc = 'best')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss values')\n",
        "  plt.grid()\n",
        "  plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moFEmYeQfPPa",
        "colab_type": "text"
      },
      "source": [
        "**Print accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLKUPevbfS-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_accuracy(train_acc, val_acc, train_title, val_title):\n",
        "  plt.plot(train_acc, 'r',label = train_title)\n",
        "  plt.plot(val_acc,   'g', label = val_title)\n",
        "  plt.legend(loc = 'best')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy values')\n",
        "  plt.grid()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05hUsKzNxy0h",
        "colab_type": "text"
      },
      "source": [
        "**Test function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIrP_Rw8x4Qx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(test_net, dataloader, dataset):\n",
        "  net = test_net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "  running_corrects = 0\n",
        "  for images, labels in tqdm(dataloader):\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(dataset))\n",
        "\n",
        "  print('Test Accuracy: {}'.format(accuracy))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87QcJlfWnVaY",
        "colab_type": "text"
      },
      "source": [
        "**Final Train and Test with DANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pIFl6ONnWIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def final_train_and_test_dann(best_lr, best_batch, best_step, best_epoch, best_alpha):\n",
        "  print('best hiperparameters: ')\n",
        "  print('lr = {}' .format(best_lr))\n",
        "  print('batch size = {}' .format(best_batch))\n",
        "  print('step size = {}' .format(best_step))\n",
        "  print('epoch = {}' .format(best_epoch))\n",
        "  print('alpha = {}' .format(best_alpha))\n",
        "\n",
        "  #define the net\n",
        "  dann_net = dann(pretrained = True)\n",
        "  dann_net.Gy[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "  dann_net.Gd[6] = nn.Linear(4096, NUM_DOMAINS)\n",
        "\n",
        "  dann_net.Gd[1].weight.data = copy.deepcopy(dann_net.Gy[1].weight.data)\n",
        "  dann_net.Gd[1].bias.data   = copy.deepcopy(dann_net.Gy[1].bias.data)\n",
        "\n",
        "  dann_net.Gd[4].weight.data = copy.deepcopy(dann_net.Gy[4].weight.data)\n",
        "  dann_net.Gd[4].bias.data   = copy.deepcopy(dann_net.Gy[4].bias.data)\n",
        "  dann_net = dann_net.to(DEVICE)\n",
        "\n",
        "  parameters_to_optimize = dann_net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr = best_lr, momentum = MOMENTUM, weight_decay = WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = best_step, gamma = GAMMA)\n",
        "\n",
        "  source_dataloader        = DataLoader(source_dataset, batch_size = best_batch, shuffle = True,  num_workers = 4, drop_last = True)\n",
        "  target_dataloader        = DataLoader(target_dataset, batch_size = best_batch, shuffle = False, num_workers = 4)\n",
        "\n",
        "  j = 0 \n",
        "  current_step = 0\n",
        "\n",
        "  cudnn.benchmark\n",
        "  n_loss_print = len(source_dataloader)\n",
        "  \n",
        "  accuracies_Gy = np.empty(NUM_EPOCHS_DANN)\n",
        "\n",
        "  losses_Gy = np.empty(NUM_EPOCHS_DANN)\n",
        "  losses_Gd_source = np.empty(NUM_EPOCHS_DANN)\n",
        "  losses_Gd_target = np.empty(NUM_EPOCHS_DANN)\n",
        "\n",
        "  # Start iterating over the epochs\n",
        "  for epoch in range(NUM_EPOCHS_DANN):\n",
        "    print('Starting epoch {}/{}, LR = {}, batch size = {}, alpha = {}'.format(epoch+1, NUM_EPOCHS_DANN, scheduler.get_lr(), best_batch, best_alpha))\n",
        "    target_dataloader_iterator = iter(target_dataloader)\n",
        "    running_loss_Gy = 0.0\n",
        "    running_loss_Gd_source = 0.0\n",
        "    running_loss_Gd_target = 0.0\n",
        "    # Iterate over the dataset\n",
        "    for source_images, source_labels in source_dataloader:\n",
        "      \n",
        "      source_images = source_images.to(DEVICE)\n",
        "      source_labels = source_labels.to(DEVICE)\n",
        "\n",
        "      \n",
        "      dann_net.train() # Sets module in training mode\n",
        "      optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "      # First step\n",
        "      outputs = dann_net.forward(source_images) # forward pass\n",
        "      loss_Gy = criterion(outputs, source_labels)\n",
        "      running_loss_Gy += loss_Gy.item()\n",
        "      if current_step % LOG_FREQUENCY == 0:\n",
        "        print('Step {}, Loss_Gy {}'.format(current_step, loss_Gy.item()))\n",
        "      loss_Gy.backward()  \n",
        "\n",
        "      #Second step\n",
        "      outputs = dann_net.forward(source_images, alpha) #backward pass\n",
        "      domain_labels = torch.zeros(source_labels.size(0), dtype=torch.int64).to(DEVICE)\n",
        "      loss_Gd_source = criterion(outputs, domain_labels)\n",
        "      running_loss_Gd_source += loss_Gd_source.item()\n",
        "      if current_step % LOG_FREQUENCY == 0:\n",
        "        print('Step {}, Loss_Gd(source data) {}'.format(current_step, loss_Gd_source.item()))\n",
        "      loss_Gd_source.backward()\n",
        "\n",
        "      #third step\n",
        "      try:\n",
        "          target_images, target_lables = next(target_dataloader_iterator)\n",
        "      except:\n",
        "          target_dataloader_iterator = iter(target_dataloader)\n",
        "          target_images, target_lables = next(target_dataloader_iterator)\n",
        "      target_images = target_images.to(DEVICE)\n",
        "      target_lables = target_lables.to(DEVICE)\n",
        "      domain_labels = torch.ones(target_lables.size(0), dtype=torch.int64).to(DEVICE)\n",
        "      outputs = dann_net.forward(target_images, alpha) #backward pass\n",
        "      loss_Gd_target = criterion(outputs, domain_labels)\n",
        "      running_loss_Gd_target += loss_Gd_target.item()\n",
        "      if current_step % LOG_FREQUENCY == 0:\n",
        "        print('Step {}, Loss_Gd(target data) {}'.format(current_step, loss_Gd_target.item()))  \n",
        "      loss_Gd_target.backward()\n",
        "\n",
        "      optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "      current_step += 1\n",
        "    losses_Gy[j]        = running_loss_Gy        / n_loss_print\n",
        "    losses_Gd_source[j] = running_loss_Gd_source / n_loss_print\n",
        "    losses_Gd_target[j] = running_loss_Gd_target / n_loss_print\n",
        "    accuracies_Gy[j] = test_accuracy(dann_net, source_dataloader, 'source')  # at each epoch\n",
        "    j += 1\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        " \n",
        "  plt.plot(accuracies_Gy, 'r',label = 'Accuracy on Source(photo)')\n",
        "  plt.legend(loc = 'best')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy values')\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "  print_loss(losses_Gy, 'Training loss(object Classifier)')\n",
        "  print_loss(losses_Gd_source, 'Training loss(Domain Discriminator photo)')\n",
        "  print_loss(losses_Gd_target, 'Training loss(Domain Discriminator art painting)')\n",
        " \n",
        "\n",
        "  test(dann_net, target_dataloader, target_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "**Train with AlexNet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "mean_accuracy_best = 0\n",
        "mean_accuracy_curr = 0\n",
        "best_accuracy_train = []\n",
        "best_accuracy_val_c = []\n",
        "best_accuracy_val_s = []\n",
        "best_loss = []\n",
        "best_lr = 0 \n",
        "best_batch = 0\n",
        "best_step = 0\n",
        "best_epoch = 0\n",
        "i = 0\n",
        "\n",
        "for i in range(len(LR)):\n",
        "  #define the net\n",
        "  alexnet_net = alexnet(pretrained = True) \n",
        "  alexnet_net.classifier[6] = nn.Linear(4096, NUM_CLASSES) \n",
        "  alexnet_net = alexnet_net.to(DEVICE) \n",
        "\n",
        "  n_epoch = NUM_EPOCHS[i]              \n",
        "  learning_rate = LR[i]      \n",
        "  ss = STEP_SIZE[i]                  \n",
        "  bs = BATCH_SIZE[i]    \n",
        "\n",
        "  alexnet_loss = np.empty(n_epoch)     \n",
        "  j = 0 \n",
        "  current_step = 0\n",
        "  accuracies_train = np.empty(n_epoch)\n",
        "  accuracies_val_cartoon = np.empty(n_epoch)\n",
        "  accuracies_val_sketch = np.empty(n_epoch)\n",
        "\n",
        "  train_dataloader         = DataLoader(train_dataset, batch_size = bs, shuffle = True,  num_workers = 4, drop_last = True)\n",
        "  val_dataloader_cartoon   = DataLoader(val_cartoon,   batch_size = bs, shuffle = True,  num_workers = 4)\n",
        "  val_dataloader_sketch    = DataLoader(val_sketch,   batch_size = bs, shuffle = True,  num_workers = 4)\n",
        "\n",
        "  n_loss_print = len(train_dataloader)\n",
        "  cudnn.benchmark\n",
        "  parameters_to_optimize = alexnet_net.parameters()\n",
        "  optimizer = optim.SGD(parameters_to_optimize, lr = learning_rate, momentum = MOMENTUM, weight_decay = WEIGHT_DECAY)\n",
        "  scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = ss, gamma = GAMMA)\n",
        "\n",
        "  # Start iterating over the epochs\n",
        "  for epoch in range(n_epoch):\n",
        "    print('Starting epoch {}/{}, LR = {}, batch size = {}'.format(epoch+1, n_epoch, scheduler.get_lr(), bs))\n",
        "    running_loss = 0.0\n",
        "    # Iterate over the dataset\n",
        "    for images, labels in train_dataloader:\n",
        "      # Bring data over the device of choice\n",
        "      images = images.to(DEVICE)\n",
        "      labels = labels.to(DEVICE)\n",
        "\n",
        "      alexnet_net.train() \n",
        "\n",
        "      optimizer.zero_grad() \n",
        "\n",
        "      outputs = alexnet_net(images)\n",
        "\n",
        "      loss = criterion(outputs, labels)\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      if current_step % LOG_FREQUENCY == 0:\n",
        "        print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "      # Compute gradients for each layer and update weights\n",
        "      loss.backward()  # backward pass: computes gradients\n",
        "      optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "      current_step += 1\n",
        "    alexnet_loss[j] = running_loss / n_loss_print\n",
        "    accuracies_train[j] = test_accuracy(alexnet_net, train_dataloader, 'train')  \n",
        "\n",
        "    #EVALUATION ON VALIDATION\n",
        "    accuracies_val_cartoon[j] = test_accuracy(alexnet_net, val_dataloader_cartoon, 'validation on cartoon')  \n",
        "    accuracies_val_sketch[j] = test_accuracy(alexnet_net, val_dataloader_sketch, 'validation on sketch')  \n",
        "    print('accuracies_val_sketch[{}] = {}'.format(j, accuracies_val_sketch[j]))\n",
        "    print('accuracies_val_cartoon[{}] = {}'.format(j, accuracies_val_cartoon[j]))\n",
        "\n",
        "\n",
        "    j += 1\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "  #I use the last values of accuracy on cartoon and sketch for the computation of the average\n",
        "  mean_accuracy_curr = (accuracies_val_cartoon[j - 1] + accuracies_val_sketch[j - 1]) /2\n",
        "  print('mean accuracy curr = {} + {} / 2 = {}'.format(accuracies_val_cartoon[j - 1], accuracies_val_sketch[j - 1], mean_accuracy_curr))\n",
        "  if(mean_accuracy_curr > mean_accuracy_best):\n",
        "    mean_accuracy_best = mean_accuracy_curr\n",
        "    best_lr = learning_rate\n",
        "    best_batch = bs\n",
        "    best_step = ss\n",
        "    best_epoch = n_epoch \n",
        "    best_alexnet_net = copy.deepcopy(alexnet_net)\n",
        "    best_accuracy_train = copy.deepcopy(accuracies_train)\n",
        "    best_accuracy_val_c = copy.deepcopy(accuracies_val_cartoon)\n",
        "    best_accuracy_val_s = copy.deepcopy(accuracies_val_sketch)\n",
        "    best_loss = copy.deepcopy(alexnet_loss)\n",
        "\n",
        "\n",
        "\n",
        "print('best mean accuracy: {}'.format(mean_accuracy_best))\n",
        "print('best hiperparameters: ')\n",
        "print('lr = {}' .format(best_lr))\n",
        "print('batch size = {}' .format(best_batch))\n",
        "print('step size = {}' .format(best_step))\n",
        "print('epoch = {}' .format(best_epoch))\n",
        "\n",
        "print_loss(best_loss, 'Training loss') \n",
        "print_accuracy(best_accuracy_train, best_accuracy_val_c, 'Accuracy on Train', 'Accuracy on validation(Cartoon)')  \n",
        "print_accuracy(best_accuracy_train, best_accuracy_val_s, 'Accuracy on Train', 'Accuracy on validation(Sketch)')\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,  batch_size = best_batch, shuffle = False, num_workers = 4)\n",
        "test(best_alexnet_net, test_dataloader, test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBKF7MelDiJg",
        "colab_type": "text"
      },
      "source": [
        "**Train with dann**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIZCLCIwDhx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "mean_accuracy_best = 0\n",
        "mean_accuracy_curr_cartoon = 0\n",
        "mean_accuracy_curr_sketch = 0\n",
        "best_lr = 0 \n",
        "best_batch = 0\n",
        "best_alpha = 0\n",
        "\n",
        "i = 0\n",
        "\n",
        "\n",
        "for i in range(len(BATCH_SIZE_DANN)):\n",
        "\n",
        "\n",
        "  bs = BATCH_SIZE_DANN[i] \n",
        "  source_dataloader        = DataLoader(source_dataset, batch_size = bs, shuffle = True,  num_workers = 4, drop_last = True)\n",
        "  target_dataloader        = DataLoader(target_dataset, batch_size = bs, shuffle = False, num_workers = 4)\n",
        "  val_dataloader_cartoon   = DataLoader(val_cartoon,    batch_size = bs, shuffle = True,  num_workers = 4)\n",
        "  val_dataloader_sketch    = DataLoader(val_sketch,     batch_size = bs, shuffle = True,  num_workers = 4)\n",
        "  validations = [val_dataloader_cartoon, val_dataloader_sketch]\n",
        "  cudnn.benchmark\n",
        "  \n",
        "  n_loss_print = len(source_dataloader)\n",
        "  k = 0\n",
        "\n",
        "  for k in range(len(LR_DANN)): \n",
        "    learning_rate = LR_DANN[k]  \n",
        "\n",
        "\n",
        "    n = 0\n",
        "   \n",
        "    for n in range(len(ALPHA)):\n",
        "      alpha = ALPHA[n]  \n",
        "      flag = 0\n",
        "\n",
        "      accuracies_Gy_cartoon = np.empty(NUM_EPOCHS_DANN)#accuracy on object classifier on photo when the validation is cartoon   \n",
        "      accuracies_Gy_sketch = np.empty(NUM_EPOCHS_DANN)#accuracy on object classifier on photo when the validation is sketch\n",
        "      losses_Gy_cartoon = np.empty(NUM_EPOCHS_DANN)\n",
        "      losses_Gy_sketch = np.empty(NUM_EPOCHS_DANN)\n",
        "\n",
        "      accuracies_val_cartoon = np.empty(NUM_EPOCHS_DANN)\n",
        "      accuracies_val_sketch = np.empty(NUM_EPOCHS_DANN)\n",
        "\n",
        "      \n",
        "      losses_Gd_source_cartoon = np.empty(NUM_EPOCHS_DANN) #accuracy on photo when the validation is cartoon\n",
        "      losses_Gd_source_sketch = np.empty(NUM_EPOCHS_DANN) #accuracy on photo when the validation is sketch\n",
        "      losses_Gd_target_cartoon = np.empty(NUM_EPOCHS_DANN)\n",
        "      losses_Gd_target_sketch = np.empty(NUM_EPOCHS_DANN)\n",
        "      for val_dataloader in validations:\n",
        "        #define the net\n",
        "        dann_net = dann(pretrained = True)\n",
        "        dann_net.Gy[6] = nn.Linear(4096, NUM_CLASSES)\n",
        "        dann_net.Gd[6] = nn.Linear(4096, NUM_DOMAINS)\n",
        "\n",
        "        dann_net.Gd[1].weight.data = copy.deepcopy(dann_net.Gy[1].weight.data)\n",
        "        dann_net.Gd[1].bias.data   = copy.deepcopy(dann_net.Gy[1].bias.data)\n",
        "\n",
        "        dann_net.Gd[4].weight.data = copy.deepcopy(dann_net.Gy[4].weight.data)\n",
        "        dann_net.Gd[4].bias.data   = copy.deepcopy(dann_net.Gy[4].bias.data)\n",
        "        dann_net = dann_net.to(DEVICE)\n",
        "\n",
        "        parameters_to_optimize = dann_net.parameters() \n",
        "        optimizer = optim.SGD(parameters_to_optimize, lr = learning_rate, momentum = MOMENTUM, weight_decay = WEIGHT_DECAY)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = STEP_SIZE_DANN, gamma = GAMMA)\n",
        "        \n",
        "        j = 0 \n",
        "        current_step = 0\n",
        "\n",
        "\n",
        "        # Start iterating over the epochs\n",
        "        for epoch in range(NUM_EPOCHS_DANN):\n",
        "          print('Starting epoch {}/{}, LR = {}, batch size = {}, alpha = {}'.format(epoch+1, NUM_EPOCHS_DANN, scheduler.get_lr(), bs, alpha))\n",
        "          target_dataloader_iterator = iter(val_dataloader)\n",
        "          running_loss_Gy = 0.0\n",
        "          running_loss_Gd_source = 0.0\n",
        "          running_loss_Gd_target = 0.0\n",
        "          # Iterate over the dataset\n",
        "          for source_images, source_labels in source_dataloader:\n",
        "            \n",
        "            source_images = source_images.to(DEVICE)\n",
        "            source_labels = source_labels.to(DEVICE)\n",
        "\n",
        "            \n",
        "            dann_net.train() # Sets module in training mode\n",
        "            optimizer.zero_grad() # Zero-ing the gradients\n",
        "\n",
        "            # First step\n",
        "            outputs = dann_net.forward(source_images) # forward pass\n",
        "            loss_Gy = criterion(outputs, source_labels)\n",
        "            running_loss_Gy += loss_Gy.item()\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "              print('Step {}, Loss_Gy {}'.format(current_step, loss_Gy.item()))\n",
        "            loss_Gy.backward()  \n",
        "\n",
        "            #Second step\n",
        "            outputs = dann_net.forward(source_images, alpha) #backward pass\n",
        "            domain_labels = torch.zeros(source_labels.size(0), dtype=torch.int64).to(DEVICE)\n",
        "            loss_Gd_source = criterion(outputs, domain_labels)\n",
        "            running_loss_Gd_source += loss_Gd_source.item()\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "              print('Step {}, Loss_Gd(source data) {}'.format(current_step, loss_Gd_source.item()))\n",
        "            loss_Gd_source.backward()\n",
        "\n",
        "            #third step\n",
        "            try:\n",
        "                target_images, target_lables = next(target_dataloader_iterator)\n",
        "            except:\n",
        "                target_dataloader_iterator = iter(val_dataloader)\n",
        "                target_images, target_lables = next(target_dataloader_iterator)\n",
        "            target_images = target_images.to(DEVICE)\n",
        "            target_lables = target_lables.to(DEVICE)\n",
        "            domain_labels = torch.ones(target_lables.size(0), dtype=torch.int64).to(DEVICE)\n",
        "            outputs = dann_net.forward(target_images, alpha) #backward pass\n",
        "            loss_Gd_target = criterion(outputs, domain_labels)\n",
        "            running_loss_Gd_target += loss_Gd_target.item()\n",
        "            if current_step % LOG_FREQUENCY == 0:\n",
        "              print('Step {}, Loss_Gd(target data) {}'.format(current_step, loss_Gd_target.item()))  \n",
        "            loss_Gd_target.backward()\n",
        "\n",
        "            optimizer.step() \n",
        "\n",
        "            current_step += 1\n",
        "          if(flag == 0):\n",
        "            losses_Gy_cartoon[j] = running_loss_Gy / n_loss_print # loss on classifier on photo when validation is cartoon\n",
        "            accuracies_Gy_cartoon[j] = test_accuracy(dann_net, source_dataloader, 'source')  # accuracy on classifier on photo when validation is cartoon\n",
        "            losses_Gd_source_cartoon[j] = running_loss_Gd_source / n_loss_print #loss on domain discriminator(source) when the validation is cartoon\n",
        "            losses_Gd_target_cartoon[j] = running_loss_Gd_target / n_loss_print #loss on domain discriminator(target) when the validation is cartoon\n",
        "            accuracies_val_cartoon[j] = test_accuracy(dann_net, val_dataloader_cartoon, 'validation on cartoon')  # accuracy on domain discriminator when the validation in cartoon\n",
        "            print('accuracies_val_cartoon[{}] = {}'.format(j, accuracies_val_cartoon[j]))\n",
        "            \n",
        "          else:\n",
        "            losses_Gy_sketch[j] = running_loss_Gy / n_loss_print # loss on classifier on photo when validation is sketch\n",
        "            accuracies_Gy_sketch[j] = test_accuracy(dann_net, source_dataloader, 'source')  # accuracy on classifier on photo when validation is sketch\n",
        "            losses_Gd_source_sketch[j] = running_loss_Gd_source / n_loss_print #loss on domain discriminator when the validation is sketch\n",
        "            losses_Gd_target_sketch[j] = running_loss_Gd_target / n_loss_print #loss on domain discriminator(target) when the validation is sketch\n",
        "            accuracies_val_sketch[j] = test_accuracy(dann_net, val_dataloader_sketch, 'validation on sketch')  # at each epoch\n",
        "            print('accuracies_val_sketch[{}] = {}'.format(j, accuracies_val_sketch[j]))\n",
        "          j += 1\n",
        "\n",
        "          # Step the scheduler\n",
        "          scheduler.step()\n",
        "        flag = 1 \n",
        "      mean_accuracy_curr = (accuracies_val_cartoon[j - 1] + accuracies_val_sketch[j - 1]) / 2\n",
        "      print('value of j = {}'.format(j))\n",
        "      print('mean accuracy curr = {} + {} / 2 = {}'.format(accuracies_val_cartoon[j - 1], accuracies_val_sketch[j - 1], mean_accuracy_curr))\n",
        "      if(mean_accuracy_curr > mean_accuracy_best):\n",
        "        mean_accuracy_best = mean_accuracy_curr\n",
        "        best_lr = learning_rate\n",
        "        best_batch = bs\n",
        "        best_alpha = alpha\n",
        "        #values of cartoon\n",
        "        best_loss_Gy_c_dann = copy.deepcopy(losses_Gy_cartoon)\n",
        "        best_acc_Gy_c_dann = copy.deepcopy(accuracies_Gy_cartoon)\n",
        "        best_loss_Gd_s_c_dann = copy.deepcopy(losses_Gd_source_cartoon)\n",
        "        best_loss_Gd_t_c_dann = copy.deepcopy(losses_Gd_target_cartoon)\n",
        "        best_acc_val_c_dann = copy.deepcopy(accuracies_val_cartoon)\n",
        "        #values of sketch\n",
        "        best_loss_Gy_sk__dann = copy.deepcopy(losses_Gy_sketch)\n",
        "        best_acc_Gy_sk_dann = copy.deepcopy(accuracies_Gy_sketch)\n",
        "        best_loss_Gd_s_sk_dann = copy.deepcopy(losses_Gd_source_sketch)\n",
        "        best_loss_Gd_t_sk_dann = copy.deepcopy(losses_Gd_target_sketch)\n",
        "        best_acc_val_sk_dann = copy.deepcopy(accuracies_val_sketch)\n",
        "      \n",
        "print('best mean accuracy: {}'.format(mean_accuracy_best))\n",
        "print('best hiperparameters: ')\n",
        "print('lr = {}' .format(best_lr))\n",
        "print('batch size = {}' .format(best_batch))\n",
        "print('step size = {}' .format(STEP_SIZE_DANN))\n",
        "print('epoch = {}' .format(NUM_EPOCHS_DANN))\n",
        "print('alpha = {}' .format(best_alpha))\n",
        "#print of loss and accuracy of the best net (validation)\n",
        "print_loss(best_loss_Gy_c_dann, 'Source loss Gy(cartoon)') \n",
        "print_loss(best_loss_Gy_sk__dann, 'Source loss Gy(sketch)') \n",
        "\n",
        "print_loss(best_loss_Gd_s_c_dann, 'Source loss Gd(cartoon)') \n",
        "print_loss(best_loss_Gd_s_sk_dann, 'Source loss Gd(sketch)')\n",
        "\n",
        "print_loss(best_loss_Gd_t_c_dann, 'Target loss Gd(cartoon)') \n",
        "print_loss(best_loss_Gd_t_sk_dann, 'Target loss Gd(sketch)') \n",
        "\n",
        "print_accuracy(best_acc_Gy_c_dann, best_acc_val_c_dann, 'Accuracy on Source(photo)', 'Accuracy on Validation(Cartoon)')  \n",
        "print_accuracy(best_acc_Gy_sk_dann, best_acc_val_sk_dann, 'Accuracy on Source(photo)', 'Accuracy on Validation(Sketch)')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSO-90_Fftgz",
        "colab_type": "text"
      },
      "source": [
        "**Evaluation of DANN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hm5lGvE3n-jV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "        best_lr = 0.005 \n",
        "        best_batch = 128\n",
        "        best_alpha = 0.1\n",
        "        final_train_and_test_dann(best_lr, best_batch, STEP_SIZE_DANN, NUM_EPOCHS_DANN, best_alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}